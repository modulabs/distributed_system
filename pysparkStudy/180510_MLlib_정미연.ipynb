{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. MLLib\n",
    "=============\n",
    "\n",
    "* * *\n",
    "\n",
    "#### 작성 : 데이터랩 3반 정미연\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 개요\n",
    "- 머신러닝 : 어떤 주어진 문제를 해결할 때, 필요한 프로그램을 일일이 작성하지 않더라도 *기계 스스로* 데이터를 이용해 문제를 해결할 수 있는 알고리즘을 만드는 것\n",
    "- 회귀, 분류, 그룹화, 추천 등 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 관측과 특성\n",
    "- feature는? 관측 데이터의 속성을 나타내는 것 (변수), 그렇지만 목표에 따라 최종 특성은 달라질 수 있음\n",
    "- 특징 추출이 핵심 활동 중 하나임. 업무 도메인 지식도 필요\n",
    "- 데이터의 변환, 필터링, 정규화, 특성 간 상관관계 분석 등을 포함함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 레이블\n",
    "- 올바른 출력값을 알려주는 값을 *레이블*이라고 함\n",
    "- 지도학습 : 입력에 대한 올바른 출력 값을 알고 있는 데이터셋에서의 입,출력을 학습하고 답이 알려지지 않은 새로운 입력값에 대한 출력값을 찾게 함 (레이블이 있음)\n",
    "- 스파크에서는 LabeledPoint라는 데이터 타입을 사용하여 레이블이 달린 데이터셋을 핸들링함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 연속형 데이터와 이산형 데이터\n",
    "- 연속형 데이터(Continuous) : 연속적인 값을 가진 것 (무게, 온도, 습도 등)\n",
    "- 이산형 데이터(Discrete data) : 불연속적인 값을 가진 것(셀 수 있음)(나이, 성별, 개수 등)\n",
    "\n",
    "- 연속형 데이터는 *실수*값, 이산형 데이터는 *정수,문자*값을 갖는데 스파크에서는 *double*타입의 데이터만 사용할 수 있음. 대신에 이를 활용할 수 있는 다양한 알고리즘을 구현한 API를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 알고리즘과 모델\n",
    "- 알고리즘 : 우리가 알고있는 그런 알고리즘들..(로지스틱 회귀, SVM, NN..)\n",
    "- 모델 : 알고리즘의 산출물임. 알고리즘에 데이터를 적용한 것.\n",
    "- 알고리즘에서 모델을 만드는 과정은 많은 자원들을 필요로 하지만 만들고 나서는 입력만 하면 결과를 빨리 얻는다! 스파크에서도 여러가지 기능 제공 중"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6 파라메트릭 알고리즘\n",
    "- 머신러닝의 궁극적인 목적은 입력 데이터로부터 원하는 출력값을 얻는 것임.\n",
    "\n",
    "- 모수적(Parametric) 알고리즘\n",
    "  - 고정된 개수의 파라미터, 계수를 사용하는 것으로 입력과 출력 사이의 관계를 특성 값에 관한 수학적 함수 또는 수식으로 가정하고, 수식의 결과가 실제 결괏값에 가깝도록 계수륵 조정하는 방법\n",
    "  - Y = a0 + a1X + e 에서 실제값-예측값을 나타내는 손실함수를 정의하여 이 함수를 최소화하는 a0, a1값을 찾아내는 것을 생각해 보자.\n",
    "  - 선형회귀, 로지스틱 회귀가 대표적임  \n",
    "\n",
    "- 비모수적(Non-parametric) 알고리즘\n",
    "  - 입력과 출력 사이의 가설이 없이 수행 결과를 그대로 사용\n",
    "  - 서포트 벡터 머신, 나이브 베이즈 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7 지도학습과 비지도학습\n",
    "\n",
    "입력 데이터의 타입 또는 예측을 수행하는 방식에 따라 학습을 나누었음\n",
    "* * *\n",
    "- 지도학습\n",
    "  - 훈련 데이터에 레이블(정답)이 포함되어 있고 입출력 가설과 레입르을 이용해 오차를 계산하고 입출력 관계를 유추\n",
    "  - 일반적으로 회귀, 분류 등.\n",
    "  - 훈련 데이터에 레이블 꼭 있어야 함\n",
    "  \n",
    "- 비지도학습 \n",
    "  - 특성과 레이블 간의 인과 관계를 모르거나, 지정해두지 않음\n",
    "  - 군집 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.8 훈련 데이터와 테스트 데이터\n",
    "\n",
    "- 지도 학습에서는 데이터를 트레이닝(훈련)/ 테스트 데이터로 나누어서 작업\n",
    "  - 트레이닝 : 모델 생성용\n",
    "  - 테스트 : 모델 성능 측정용\n",
    "  - 트레이닝 셋과 테스트 셋을 명확히 구분해야 하며, 교차검증(데이터셋을 토막내서 테스트셋, 트레이닝셋 토막을 바꿔가며 진행) 등의 방법으로도 효율을 높임\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.9 MLlib API\n",
    "#### 제공 API\n",
    "1. 머신러닝 알고리즘 : 분류, 회귀, 클러스터링, 협업 필터링 등 제공\n",
    "2. 특성 추출, 변환, 선택 AP 제공\n",
    "3. 파이프라인 : 순차적으로 수행할 수 있는 파이프라인 API 제공\n",
    "4. 저장 : 알고리즘, 모델, 파이프라인에 대한 저장 및 불러오기 기능\n",
    "5. 유틸리티 : 선형대수, 통계, 데이터 처리 등 함수 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.10 의존성 설정\n",
    "\n",
    "- 스파크 MLlib을 사용하기 위한 **의존성 설정**이 필요\n",
    "\n",
    "###### 의존성이란?\n",
    "- 코드에서 두 모듈 간의 연결.\n",
    "- 객체지향언어에서는 두 클래스 간의 관계라고도 말함.\n",
    "- 일반적으로 둘 중 하나가 다른 하나를 어떤 용도를 위해 사용함.\n",
    "\n",
    "출처: <http://tony-programming.tistory.com/entry/Dependency-의존성-이란> [Tony Programming]\n",
    "\n",
    "- 스파크는 선형대수 라이브러리 breeze를 사용하는데, 처리 속도 향상을 위해 netlib-java에 의존성이 있어 아나콘다가 없을 시 운영체제에 맞게 따로 설치해야 함\n",
    "- 참고 깃헙은 [여기](http://www.github.com/fommil/netlib-java)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.11 벡터와 LabeledPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.11.1 벡터\n",
    "- 벡터는 double 타입의 값들을 포함하는 컬렉션으로 구현\n",
    "- 스파크 mllib의 vector는 org.apache.spark.ml.linalg 패키지에 정의된 트레이트(자바의 인터페이스와 유사, 직접 인스턴스를 생성할 수 없음)\n",
    "\n",
    "#### 생성 방법\n",
    "- DenseVector 클래스(값에 대한 정보만 있음)는 dense()\n",
    "- SparseVector(값과 값에 대한 인덱스 정보 포함)는 sparse(), 데이터에 0이 많을 경우 이쪽을 생성하는 것이 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1  0.   0.2  0.3]\n",
      "[0.1,0.0,0.2,0.3]\n",
      "[ 0.1  0.   0.2  0.3]\n",
      "(4,[0,2,3],[0.1,0.2,0.3])\n",
      "  (0, 0)\t0.1\n",
      "  (2, 0)\t0.2\n",
      "  (3, 0)\t0.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "# dense vector\n",
    "v1 = np.array([0.1, 0.0, 0.2, 0.3])\n",
    "v2 = Vectors.dense([0.1, 0.0, 0.2, 0.3])\n",
    "v3 = [0.1, 0.0, 0.2, 0.3]\n",
    "\n",
    "\n",
    "# sparse vector\n",
    "v3 = Vectors.sparse(4, [(0, 0.1), (2, 0.2), (3, 0.3)])\n",
    "v4 = Vectors.sparse(4, [0,2,3], [0.1, 0.2, 0.3])\n",
    "v5 = sps.csc_matrix((np.array([0.1, 0.2, 0.3]), np.array([0,2,3]), np.array([0,3])),shape = (4,1))\n",
    "\n",
    "print(v1)\n",
    "print(v2)\n",
    "print(v3.toArray())\n",
    "print(v4)\n",
    "print(v5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dense() 메서드\n",
    "  - 벡터에 포함할 데이터를 직접 인자로 전달, 배열을 사용해 한번에 전달\n",
    "  \n",
    "  \n",
    "- sparse() 메서드\n",
    "  - 첫번째 인자 : 전체 벡터의 크기를 지정\n",
    "  - 두번째 인자 : 0이 아닌 데이터의 위치를 나타내는 인덱스 배열 전달\n",
    "  - 마지막 인자 : 각 인덱스 위치에 해당하는 데이터를 전달"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.11.2 LabeledPoint\n",
    "- 레이블을 사용하는 경우를 위한 벡터.특성 값+레이블 포함\n",
    "- double 타입만 할당함.\n",
    "- 머신러닝 작업에서는 sparsevector를 많이 쓰기 때문에 특정 포맷을 가진 텍스트 파일로부터 이 벡터를 생성하는 유틸리티 함수를 제공함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:1.0, features:[0.1,0.0,0.2,0.3]\n"
     ]
    }
   ],
   "source": [
    "# LabeledPoint 생성\n",
    "# 아래 코드 주석을 지우면 sparsevecotr 사용이 가능합니다.\n",
    "\n",
    "## Code start\n",
    "import numpy as np\n",
    "# import scipy.sparse as sps\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "#from pyspark.mllib.util import MLUtils\n",
    "#from pyspark.sql import SparkSession\n",
    "\n",
    "#path=\"your spark dir/sample_libsvm_data.txt\"\n",
    "#v7 = MLUtils.loadLibSVMFile(spark.sparkContext, path)\n",
    "#lp1 = v7.first\n",
    "#print(\"label:%s, features:%s\" % (lp1.label, lp1.features))\n",
    "\n",
    "v1 = np.array([0.1, 0.0, 0.2, 0.3])\n",
    "v6 = LabeledPoint(1.0, v1)\n",
    "print(\"label:%s, features:%s\" % (v6.label, v6.features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.12 파이프라인\n",
    "- 데이터 수집, 가공, 특성 추출, 알고리즘 적용 및 모델 생성, 평가, 배포 활용의 작업의 처리 작업을 통함\n",
    "\n",
    "- 파이프라인은 여러 종류의 알고리즘을 *순차적으로 실행할 수 있게* 지원해줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
